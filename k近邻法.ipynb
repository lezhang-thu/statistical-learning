{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aead63a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $k$近邻法\n",
    "\n",
    "* $k$近邻法是一种基本分类与回归方法\n",
    "* 只讨论分类问题中的$k$近邻法\n",
    "* 假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其$k$个最近邻的训练实例的类别，通过多数表决等方式进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bd19a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# $k$近邻法\n",
    "\n",
    "* 不具有显式的学习过程\n",
    "* 实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f051868",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $k$近邻算法\n",
    "\n",
    "1. 根据给定的距离度量，在训练集$T$中找出与$x$最邻近的$k$个点，涵盖这上$k$个点的$x$的邻域记作$N_k(x)$\n",
    "1. 在$N_k(x)$中根据分类决策规则（如多数表决）决定$x$的类别$y$：\n",
    "$$\n",
    "y=\\mathop{\\arg\\,\\max}_{c_j}\\sum_{x_i\\in N_k(x)}I(y_i=c_j)\n",
    "$$\n",
    "\n",
    "课堂提问\\_1：$k=1$的情形"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec8330",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $k$近邻模型\n",
    "\n",
    "* 模型由三个基本要素——距离度量、$k$值的选择和分类决策规则决定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6069b7a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 距离度量\n",
    "\n",
    "* 特征空间中两个实例点的距离是两个实例点相似程度的反映\n",
    "* $x_i,x_j$的$L_p$距离定义为：\n",
    "$$\n",
    "L_p(x_i,x_j)=\\biggl(\\sum_{l=1}^n|x^{(l)}_i-x^{(l)}_j|^p\\biggr)^{\\frac{1}{p}}\n",
    "$$\n",
    "\n",
    "* 当$p=\\infty$时，它是各个坐标距离的最大值，即\n",
    "$$\n",
    "L_\\infty=\\max_l|x^{(l)}_i-x^{(l)}_j|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a28a75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 距离度量\n",
    "\n",
    "1. 课堂提问\\_2：图3.2中，$p=2$的形式；课堂提问\\_3：图3.2中，$p=1$的形式\n",
    "1. 例3.1：“所以$p$为任何值时，$L_p(x_1,x_2)=4$”。课堂提问\\_4：为什么\n",
    "1. “$p$大于等于3时，$x_3$是$x_1$的最近邻点”。课堂提问\\_5：为什么"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59e732",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$值的选择\n",
    "\n",
    "* 如果$k = N$，那么无论输入实例是什么，都将简单地预测它属于在训练实例中最多的类\n",
    "* 这时，模型过于简单，完全忽略训练实例中的大量有用信息，是不可取的\n",
    "* 在应用中，$k$值一般取一个比较小的数值。通常釆用交叉验证法来选取最优的$k$值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7095d31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $k$近邻法的实现：$kd$树\n",
    "\n",
    "* 实现$k$近邻法时，主要考虑的问题是如何对训练数据进行快速$k$近邻搜索\n",
    "* 这点在特征空间的维数大及训练数据容量大时尤其必要\n",
    "\n",
    "课堂提问\\_6：linear scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d77055",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 构造$kd$树\n",
    "\n",
    "* $kd$树是二叉树，表示对$k$维空间的一个划分（partition）\n",
    "* 构造$kd$树相当于不断地用垂直于坐标轴的超平面将$k$维空间切分，构成一系列的$k$维超矩形区域\n",
    "* $kd$树的每个结点对应于一个$kd$维超矩形区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935ef469",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from operator import itemgetter\n",
    "from pprint import pformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2553c04c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Node(namedtuple(\"Node\", \"location left_child right_child\")):\n",
    "    def __repr__(self):\n",
    "        return pformat(tuple(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0278a366",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def kdtree(point_list, depth: int = 0): \n",
    "    if not point_list:\n",
    "        return None\n",
    "\n",
    "    k = len(point_list[0])  # assumes all points have the same dimension\n",
    "    # Select axis based on depth so that axis cycles through all valid values\n",
    "    axis = depth % k \n",
    "\n",
    "    # Sort point list by axis and choose median as pivot element\n",
    "    point_list.sort(key=itemgetter(axis))\n",
    "    median = len(point_list) // 2\n",
    "\n",
    "    # Create node and construct subtrees\n",
    "    return Node(\n",
    "        location=point_list[median],\n",
    "        left_child=kdtree(point_list[:median], depth + 1), \n",
    "        right_child=kdtree(point_list[median + 1:], depth + 1), \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816ddc57",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Example usage\"\"\"\n",
    "    point_list = [(7, 2), (5, 4), (9, 6), (4, 7), (8, 1), (2, 3)]\n",
    "    tree = kdtree(point_list)\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957f4b24",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7, 2),\n",
      " ((5, 4), ((2, 3), None, None), ((4, 7), None, None)),\n",
      " ((9, 6), ((8, 1), None, None), None))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77798bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 构造$kd$树\n",
    "\n",
    "<center><img src=\"Kdtree_2d.svg\" width=\"35%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e056e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 构造$kd$树\n",
    "\n",
    "<center><img src=\"Tree_0001.svg\" width=\"50%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1eefe3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 搜索$kd$树\n",
    "\n",
    "1. 在$kd$树中找出包含目标点$x$的叶结点\n",
    "1. 以此叶结点为“当前最近点”\n",
    "1. 递归地向上回退，在每个结点进行以下操作：\n",
    "    1. 如果该结点保存的实例点比“当前最近点”距离目标点更近，则以该实例点为“当前最近点”\n",
    "    1. 检査该子结点的父结点的另一子结点$y$对应的区域$R$是否有更近的点\n",
    "        1. 如果不相交，区域$R$被**eliminated**\n",
    "        1. 如果相交，返回第1步，作用在以$y$为root的$kd$树上\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04b69d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 搜索$kd$树\n",
    "\n",
    "* 区域$R$被**eliminated**\n",
    "* Since the hyperplanes are all axis-aligned this is implemented as a simple comparison to see whether the distance between the splitting coordinate of the search point and current node is lesser than the distance (overall coordinates) from the search point to the current best."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
