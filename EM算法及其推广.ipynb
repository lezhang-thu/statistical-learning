{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32cad74b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EM算法及其推广\n",
    "\n",
    "* EM算法是一种迭代算法，1977年由Dempster等人总结提出，用于含有隐变量（hidden variable）的概率模型参数的极大似然估计，或极大后验概率估计\n",
    "* EM算法的每次迭代由两步组成：\n",
    "    1. E步，求期望(expectation)\n",
    "    1. M步，求极大 (maximization)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518af37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的引入\n",
    "\n",
    "* 概率模型有时既含有观测变量（observable variable），又含有隐变量或潜在变量（latent variable）\n",
    "* EM算法就是含有**隐变量**的概率模型参数的极大似然估计法，或极大后验概率估计法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4d4e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "* 一般地，用$Y$表示观测随机变量的数据，$Z$表示隐随机变量的数据\n",
    "* $Y$和$Z$连在一起称为完全数据（complete-data）\n",
    "* 观测数据$Y$又称为不完全数据（incomplete-data）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83693a20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "* 假设给定观测数据$Y$，其概率分布是$P(Y|\\theta)$，其中$\\theta$是需要估计的模型参数，那么不完全数据$Y$的似然函数是$P(Y|\\theta)$\n",
    "* 假设$Y$和$Z$的联合概率分布是$P(Y,Z|\\theta)$，那么完全数据的对数似然函数是$\\log P(Y,Z|\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09a83e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "* 目标是极大化观测数据（不完全数据）$Y$关于参数$\\theta$的对数似然函数，即极大化\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\theta)&=\\log P(Y|\\theta)\\\\\n",
    "         &=\\log \\sum_Z P(Y,Z|\\theta)\\\\\n",
    "         &=\\log\\biggl(\\sum_Z P(Y|Z,\\theta)P(Z|\\theta)\\biggr)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d61d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "* \n",
    "\n",
    "$$\n",
    "\\log\\biggl(\\sum_Z P(Y|Z,\\theta)P(Z|\\theta)\\biggr)\n",
    "$$\n",
    "\n",
    "* 注意到这一极大化的主要困难是上式中有未观测数据并有包含和（或积分）的对数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8540fc6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "* 假设在第$i$次迭代后$\\theta$的估计值是$\\theta^{(i)}$\n",
    "* 利用Jensen不等式（Jensen inequality）得到\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\log\\biggl(\\sum_Z P(Y|Z,\\theta)P(Z|\\theta)\\biggr)&=\\log\\biggl(\\sum_Z P(Z|Y,\\theta^{(i)})\\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^{(i)})}\\biggr)\\\\\n",
    "&\\ge \\sum_Z P(Z|Y,\\theta^{(i)})\\log \\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^{(i)})}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a23e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "* \n",
    "\n",
    "$$\n",
    "L(\\theta)-L(\\theta^{(i)})\\ge \\sum_Z P(Z|Y,\\theta^{(i)})\\log \\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^{(i)})P(Y|\\theta^{(i)})}\n",
    "$$\n",
    "* 函数$B(\\theta,\\theta^{(i)})$见textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f245306",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "* $\\theta^{(i+1)}=\\mathop{\\arg\\,\\max}_\\theta B(\\theta,\\theta^{(i)})$\n",
    "*\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\theta^{(i+1)}&=\\mathop{\\arg\\,\\max}_\\theta\\biggl(\\sum_Z P(Z|Y,\\theta^{(i)})\\log P(Y,Z|\\theta)\\biggr)\\\\\n",
    "&=\\mathop{\\arg\\,\\max}_\\theta Q(\\theta,\\theta^{(i)})\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439bb22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "Q(\\theta,\\theta^{(i)})&=\\sum_Z P(Z|Y,\\theta^{(i)})\\log P(Y,Z|\\theta)\\\\\n",
    "&=\\mathop{\\mathbb{E}}_Z [\\log P(Y,Z|\\theta)\\mid Y,\\theta^{(i)}]\n",
    "\\end{split}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c812c9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法在高斯混合模型学习中的应用\n",
    "\n",
    "### 高斯混合模型\n",
    "\n",
    "* \n",
    "\n",
    "$$\n",
    "P(y|\\theta)=\\sum_{k=1}^K\\alpha_k\\phi(y|\\theta_k)\n",
    "$$\n",
    "其中$\\phi(y|\\theta_k)$是高斯分布密度，$\\theta_k=(\\mu_k,\\sigma^2_k)$\n",
    "\n",
    "$$\n",
    "\\phi(y|\\theta_k)=\\frac{1}{\\sqrt{2\\pi}\\sigma_k}\\exp\\biggl(-\\frac{(y-\\mu_k)^2}{2\\sigma^2_k}\\biggr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74098c94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 高斯混合模型参数估计的EM算法\n",
    "\n",
    "* $\\theta=(\\alpha_1,\\alpha_2,\\dotsc,\\alpha_K;\\theta_1,\\theta_2,\\dotsc,\\theta_K)$\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
