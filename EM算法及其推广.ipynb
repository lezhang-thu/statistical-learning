{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32cad74b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# EM算法及其推广\n",
    "\n",
    "* 用于含有隐变量（hidden variable）的概率模型参数的极大似然估计，或极大后验概率估计\n",
    "* 每次迭代由两步组成：\n",
    "    1. E步，求期望（expectation）\n",
    "    1. M步，求极大 (maximization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518af37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的引入\n",
    "\n",
    "概率模型有时既含有观测变量（observable variable），又含有隐变量或潜在变量（latent variable）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bfff49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### EM算法\n",
    "\n",
    "三硬币模型\n",
    "\n",
    "* 模型参数$\\theta=(\\pi,p,q)$\n",
    "* $y$：表示一次试验观测的结果是1或0\n",
    "* $z$：表示未观测到的掷硬币A的结果\n",
    "* \n",
    "  \\begin{equation*}\n",
    "  \\begin{split}\n",
    "  P(y|\\theta)&=\\sum_z P(y,z|\\theta)=\\sum_z P(z|\\theta)P(y|z,\\theta)\\\\\n",
    "  &=\\pi p^y(1-p)^{1-y}+(1-\\pi)q^y(1-q)^{1-y}\n",
    "  \\end{split}\n",
    "  \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4d4e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 数据\n",
    "\n",
    "* $Y$：观测随机变量的数据\n",
    "* $Z$：隐随机变量的数据\n",
    "* 完全数据（complete-data）\n",
    "* 不完全数据（incomplete-data）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2b6986",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### EM算法\n",
    "\n",
    "* 不完全数据$Y$的似然函数是$P(Y|\\theta)$\n",
    "* 通过迭代求$L(\\theta)=\\log P(Y|\\theta)$的极大似然估计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09a83e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 主要困难\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "L(\\theta)&=\\log P(Y|\\theta)\\\\\n",
    "         &=\\log \\sum_Z P(Y,Z|\\theta)\\\\\n",
    "         &=\\log\\biggl(\\sum_Z P(Y|Z,\\theta)P(Z|\\theta)\\biggr)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "主要困难：有未观测数据并有包含和（或积分）的对数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8540fc6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "* 假设在第$i$次迭代后$\\theta$的估计值是$\\theta^{(i)}$\n",
    "* 利用Jensen不等式得到\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "&\\log\\biggl(\\sum_Z P(Y|Z,\\theta)P(Z|\\theta)\\biggr)\\\\\n",
    "&=\\log\\biggl(\\sum_Z P(Z|Y,\\theta^{(i)})\\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^{(i)})}\\biggr)\\\\\n",
    "&\\ge \\sum_Z P(Z|Y,\\theta^{(i)})\\log \\frac{P(Y|Z,\\theta)P(Z|\\theta)}{P(Z|Y,\\theta^{(i)})}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a23e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 考虑两者的差\n",
    "\n",
    "* \n",
    "\n",
    "$$\n",
    "L(\\theta)-L(\\theta^{(i)})\\ge \\sum_Z P(Z|Y,\\theta^{(i)})\\log \\frac{P(Y,Z|\\theta)}{P(Z|Y,\\theta^{(i)})P(Y|\\theta^{(i)})}\n",
    "$$\n",
    "* 函数$B(\\theta,\\theta^{(i)})$见textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f245306",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "* $\\theta^{(i+1)}=\\mathop{\\arg\\,\\max}_\\theta B(\\theta,\\theta^{(i)})$\n",
    "*\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\theta^{(i+1)}&=\\mathop{\\arg\\,\\max}_\\theta\\biggl(\\sum_Z P(Z|Y,\\theta^{(i)})\\log P(Y,Z|\\theta)\\biggr)\\\\\n",
    "&=\\mathop{\\arg\\,\\max}_\\theta Q(\\theta,\\theta^{(i)})\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439bb22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法的导出\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "Q(\\theta,\\theta^{(i)})&=\\sum_Z P(Z|Y,\\theta^{(i)})\\log P(Y,Z|\\theta)\\\\\n",
    "&=\\mathop{\\mathbb{E}}_Z [\\log P(Y,Z|\\theta)\\mid Y,\\theta^{(i)}]\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "* E步：计算$Q(\\theta,\\theta^{(i)})$\n",
    "* M步：求使$Q(\\theta,\\theta^{(i)})$极大化的$\\theta$\n",
    "* 函数$Q(\\theta,\\theta^{(i)})$是EM算法的核心，称为Q函数（Q function）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c812c9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EM算法在高斯混合模型学习中的应用\n",
    "\n",
    "### 高斯混合模型\n",
    "\n",
    "* \n",
    "\n",
    "$$\n",
    "P(y|\\theta)=\\sum_{k=1}^K\\alpha_k\\phi(y|\\theta_k)\n",
    "$$\n",
    "其中$\\phi(y|\\theta_k)$是高斯分布密度，$\\theta_k=(\\mu_k,\\sigma^2_k)$\n",
    "\n",
    "$$\n",
    "\\phi(y|\\theta_k)=\\frac{1}{\\sqrt{2\\pi}\\sigma_k}\\exp\\biggl(-\\frac{(y-\\mu_k)^2}{2\\sigma^2_k}\\biggr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74098c94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 高斯混合模型参数估计的EM算法\n",
    "\n",
    "* $\\theta=(\\alpha_1,\\alpha_2,\\dotsc,\\alpha_K;\\theta_1,\\theta_2,\\dotsc,\\theta_K)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae7a5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\begin{equation*}\n",
    "P(y,\\gamma|\\theta)=\\prod_{k=1}^K\\alpha^{n_k}_k\\prod_{j=1}^N\\biggl[\\frac{1}{\\sqrt{2\\pi}\\sigma_k}\\exp\\Bigl(-\\frac{(y_j-\\mu_k)^2}{2\\sigma^2_k}\\Bigr)\\biggr]^{\\gamma_{jk}}\n",
    "\\end{equation*}\n",
    "\n",
    "取$\\log$，第1步有：\n",
    "\n",
    "\\begin{equation*}\n",
    "\\log P(y,\\gamma|\\theta)=\\sum_{k=1}^K\\log\\bigg(\\alpha^{n_k}_k\\prod_{j=1}^N\\biggl[\\frac{1}{\\sqrt{2\\pi}\\sigma_k}\\exp\\Bigl(-\\frac{(y_j-\\mu_k)^2}{2\\sigma^2_k}\\Bigr)\\biggr]^{\\gamma_{jk}}\\biggr)\n",
    "\\end{equation*}\n",
    "\n",
    "第2步有：\n",
    "\n",
    "\\begin{equation*}\n",
    "\\sum_{k=1}^K\\bigg(\\log\\alpha^{n_k}_k+\\log\\prod_{j=1}^N\\biggl[\\frac{1}{\\sqrt{2\\pi}\\sigma_k}\\exp\\Bigl(-\\frac{(y_j-\\mu_k)^2}{2\\sigma^2_k}\\Bigr)\\biggr]^{\\gamma_{jk}}\\biggr)\n",
    "\\end{equation*}\n",
    "\n",
    "第3步有：\n",
    "\n",
    "\\begin{equation*}\n",
    "\\sum_{k=1}^K\\bigg(\\log\\alpha^{n_k}_k+\\sum_{j=1}^N\\log\\biggl[\\frac{1}{\\sqrt{2\\pi}\\sigma_k}\\exp\\Bigl(-\\frac{(y_j-\\mu_k)^2}{2\\sigma^2_k}\\Bigr)\\biggr]^{\\gamma_{jk}}\\biggr)\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c85c0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 高斯混合模型参数估计的EM算法\n",
    "\n",
    "计算$\\mathbb{E}[\\gamma_{jk}|y,\\theta^{(i)}]$\n",
    "\n",
    "* $\\gamma_{jk}$是0-1随机变量：$\\mathbb{E}[\\gamma_{jk}|y,\\theta]=P(\\gamma_{jk}=1|y,\\theta)$\n",
    "* $\\gamma_{jk}=1$：第$j$个观测来自第$k$个分模型\n",
    "\n",
    "  $P(\\gamma_{jk}=1|y,\\theta)=P(\\gamma_{jk}=1|y_j,\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d4db3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 计算$P(\\gamma_{jk}=1|y_j,\\theta^{(i)})$\n",
    "\n",
    "  \\begin{equation*}\n",
    "  P(\\gamma_{jk}=1|y_j,\\theta)=\\frac{P(\\gamma_{jk}=1,y_j|\\theta)}{P(y_j|\\theta)}\n",
    "  \\end{equation*}\n",
    "  \n",
    "* 边缘分布$P(y_j|\\theta)$\n",
    "\n",
    "  \\begin{equation*}\n",
    "  \\sum_{k'=1}^K P(\\gamma_{jk'}=1,y_j|\\theta)\n",
    "  \\end{equation*}\n",
    "* 计算$P(\\gamma_{jk}=1,y_j|\\theta)$\n",
    "\n",
    "  $P(y_j|\\gamma_{jk}=1,\\theta)P(\\gamma_{jk}=1|\\theta)$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
