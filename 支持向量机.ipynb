{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab37b34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 支持向量机\n",
    "\n",
    "* 支持向量机（support vector machines，SVM）是一种二类分类模型\n",
    "* 它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机\n",
    "* 支持向量机还包括核技巧，这使它成为实质上的非线性分类器\n",
    "* 支持向量机的学习策略就是间隔最大化，可形式化为一个求解凸二次规划（convex quadratic programming）的问题\n",
    "* 支持向量机的学习算法是求解凸二次规划的最优化算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e452757",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 支持向量机\n",
    "\n",
    "* 当训练数据线性可分时，通过硬间隔最大化（hard margin maximization），学习一个线性的分类器，即线性可分支持向量机，又称为硬间隔支持向量机\n",
    "* 当训练数据近似线性可分时，通过软间隔最大化（soft margin maximization），也学习一个线性的分类器，即线性支持向量机，又称为软间隔支持向量机\n",
    "* 当训练数据线性不可分时，通过使用核技巧（kernel trick）及软间隔最大化，学习非线性支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987d344",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 支持向量机\n",
    "\n",
    "通过使用核函数可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e8201",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 线性可分支持向量机与硬间隔最大化\n",
    "\n",
    "### 线性可分支持向量机\n",
    "\n",
    "* 假设给定一个特征空间上的训练数据集\n",
    "\n",
    "  \\begin{equation*}\n",
    "  T=\\{(x_1,y_1),(x_2,y_2),\\dotsc,(x_N,y_N)\\}\n",
    "  \\end{equation*}\n",
    "  \n",
    "  $y_i\\in\\mathcal{Y}=\\{+1,-1\\}$\n",
    "  \n",
    "* 当其$y_i=+1$时，称$x_i$为正例；当$y_i=-1$时，称$x_i$为负例\n",
    "\n",
    "* 再假设训练数据集是线性可分的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18675a5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 线性可分支持向量机\n",
    "\n",
    "* 学习的目标是在特征空间中找到一个分离超平面，能将实例分到不同的类\n",
    "* 分离超平面对应于方程$w\\cdot x+b=0$\n",
    "* 分离超平面将特征空间划分为两部分，一部分是正类，一部分是负类\n",
    "* 法向量指向的一侧为正类，另一侧为负类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc2f59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 线性可分支持向量机\n",
    "\n",
    "* 感知机利用误分类最小的策略，求得分离超平面，不过这时的解有无穷多个\n",
    "* 线性可分支持向量机利用间隔最大化求最优分离超平面，这时，解是唯一的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0636f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 线性可分支持向量机\n",
    "\n",
    "* 分类决策函数$f(x)=\\mathrm{sign}(w^*\\cdot x+b^*)$\n",
    "* (Source - Wikipedia)\n",
    "    * $H_1$不能把类别分开\n",
    "    * $H_2$可以，但只有很小的间隔\n",
    "    * $H_3$以最大间隔将它们分开\n",
    "\n",
    "<center><img src=\"img/SVM_Separating_Hyperplanes.svg\" width=\"40%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411bae6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 函数间隔和几何间隔\n",
    "\n",
    "* 一般来说，一个点距离分离超平面的远近可以表示分类预测的确信程度\n",
    "* 函数间隔：\n",
    "    * 样本点$(x_i,y_i)$：$\\hat{\\gamma}_i=y_i(w\\cdot x_i+b)$\n",
    "    * 训练数据集$T$：$\\hat{\\gamma}=\\min_{i=1,\\dots,N}\\hat{\\gamma}_i$\n",
    "* 只要成比例地改变$w$和$b$，例如将它们改为$2w$和$2b$，超平面并没有改变，但函数间隔却成为原来的2倍\n",
    "* 规范化，$\\|w\\|=1$，使得间隔是确定的\n",
    "* 几何间隔（geometric margin）\n",
    "  \n",
    "  \\begin{align*}\n",
    "  \\gamma_i&=y_i\\biggl(\\frac{w}{\\|w\\|}\\cdot x_i+\\frac{b}{\\|w\\|}\\biggr)\\\\\n",
    "  \\gamma &= \\min_{i=1,\\dots,N}\\gamma_i\n",
    "  \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e330b90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 函数间隔和几何间隔\n",
    "\n",
    "* 超平面$(w,b)$关于样本点$(x_i,y_i)$的几何间隔一般是实例点到超平面的带符号的距离（signed distance）\n",
    "* 当样本点被超平面正确分类时就是实例点到超平面的距离\n",
    "* 如果超平面参数$w$和$b$成比例地改变（超平面没有改变），函数间隔也按此比例改变，而几何间隔不变"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d297dc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 间隔最大化\n",
    "\n",
    "* 支持向量机学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面\n",
    "* 对线性可分的训练数据集而言，线性可分分离超平面有无穷多个（等价于感知机），但是几何间隔最大的分离超平面是唯一的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd296f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 间隔最大化\n",
    "\n",
    "间隔最大化的直观解释是：\n",
    "\n",
    "* 对训练数据集找到几何间隔最大的超平面意味着以充分大的确信度对训练数据进行分类\n",
    "* 也就是说，不仅将正负实例点分开，而且对最难分的实例点（离超平面最近的点）也有足够大的确信度将它们分开\n",
    "* 这样的超平面应该对未知的新实例有很好的分类预测能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dec5f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 间隔最大化\n",
    "\n",
    "**最大间隔分离超平面**\n",
    "\n",
    "\\begin{align*}\n",
    "\\max_{w,b}&\\quad \\gamma\\\\\n",
    "\\mathrm{s.t.}&\\quad y_i\\biggl(\\frac{w}{\\|w\\|}\\cdot x_i+\\frac{b}{\\|w\\|}\\biggr)\\ge \\gamma,\\quad i=1,2,\\dotsc,N\n",
    "\\end{align*}\n",
    "\n",
    "改写为：\n",
    "\n",
    "\\begin{align*}\n",
    "\\max_{w,b}&\\quad \\frac{\\hat{\\gamma}}{\\|w\\|}\\\\\n",
    "\\mathrm{s.t.}&\\quad y_i(w\\cdot x_i+b)\\ge \\hat{\\gamma},\\quad i=1,2,\\dotsc,N\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a6606d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 间隔最大化\n",
    "\n",
    "**最大间隔分离超平面**\n",
    "\n",
    "* 函数间隔$\\hat{\\gamma}$的取值并不影响最优化问题的解\n",
    "* 事实上，假设将$w$和$b$按比例改变为$\\lambda w$和$\\lambda b$，这时函数间隔成为$\\lambda \\hat{\\gamma}$\n",
    "* 函数间隔的这一改变对上面最优化问题的不等式约束没有影响，对目标函数的优化也没有影响\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{w,b}&\\quad \\frac{1}{2}\\|w\\|^2\\\\\n",
    "\\mathrm{s.t.}&\\quad y_i(w\\cdot x_i+b)-1\\ge 0,\\quad i=1,2,\\dotsc,N\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92337d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 间隔最大化\n",
    "\n",
    "**最大间隔分离超平面**\n",
    "\n",
    "凸二次规划（convex quadratic programming）问题\n",
    "\n",
    "* 当目标函数是二次函数且约束函数是仿射函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c70370",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 间隔最大化\n",
    "\n",
    "**支持向量和间隔边界**\n",
    "\n",
    "* 在线性可分情况下，训练数据集的样本点中与分离超平面距离最近的样本点的实例称为支持向量（support vector）\n",
    "  \n",
    "  \\begin{equation*}\n",
    "  y_i(w\\cdot x_i+b)-1=0\n",
    "  \\end{equation*}\n",
    "  \n",
    "* 对$y_i=+1$的正例点，支持向量在超平面$H_1:w\\cdot x+b=1$\n",
    "* 对$y_i=-1$的正例点，支持向量在超平面$H_2:w\\cdot x+b=-1$\n",
    "* Source - Wikipedia\n",
    "\n",
    "<center><img src=\"img/Svm_max_sep_hyperplane_with_margin.png\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b38e15",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 间隔最大化\n",
    "\n",
    "**支持向量和间隔边界**\n",
    "\n",
    "* 在决定分离超平面时只有支持向量起作用，而其他实例点并不起作用\n",
    "    * 如果移动支持向量将改变所求的解\n",
    "    * 但是如果在间隔边界以外移动其他实例点，甚至去掉这些点，则解是不会改变的\n",
    "* 支持向量的个数一般很少，所以支持向量机由很少的“重要的”训练样本确定"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
